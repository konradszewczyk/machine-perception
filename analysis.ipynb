{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emotions_df = pd.read_csv('data/emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># mean_0_a</th>\n",
       "      <th>mean_1_a</th>\n",
       "      <th>mean_2_a</th>\n",
       "      <th>mean_3_a</th>\n",
       "      <th>mean_4_a</th>\n",
       "      <th>mean_d_0_a</th>\n",
       "      <th>mean_d_1_a</th>\n",
       "      <th>mean_d_2_a</th>\n",
       "      <th>mean_d_3_a</th>\n",
       "      <th>mean_d_4_a</th>\n",
       "      <th>...</th>\n",
       "      <th>fft_741_b</th>\n",
       "      <th>fft_742_b</th>\n",
       "      <th>fft_743_b</th>\n",
       "      <th>fft_744_b</th>\n",
       "      <th>fft_745_b</th>\n",
       "      <th>fft_746_b</th>\n",
       "      <th>fft_747_b</th>\n",
       "      <th>fft_748_b</th>\n",
       "      <th>fft_749_b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.620</td>\n",
       "      <td>30.3</td>\n",
       "      <td>-356.0</td>\n",
       "      <td>15.60</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-15.700</td>\n",
       "      <td>2.060</td>\n",
       "      <td>3.15</td>\n",
       "      <td>...</td>\n",
       "      <td>23.50</td>\n",
       "      <td>20.300</td>\n",
       "      <td>20.300</td>\n",
       "      <td>23.50</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>280.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>-162.00</td>\n",
       "      <td>280.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.800</td>\n",
       "      <td>33.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.80</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.550</td>\n",
       "      <td>1.680</td>\n",
       "      <td>2.880</td>\n",
       "      <td>3.830</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.30</td>\n",
       "      <td>-21.800</td>\n",
       "      <td>-21.800</td>\n",
       "      <td>-23.30</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>-31.60</td>\n",
       "      <td>2.57</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.900</td>\n",
       "      <td>29.4</td>\n",
       "      <td>-416.0</td>\n",
       "      <td>16.70</td>\n",
       "      <td>23.7</td>\n",
       "      <td>79.900</td>\n",
       "      <td>3.360</td>\n",
       "      <td>90.200</td>\n",
       "      <td>89.900</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>462.00</td>\n",
       "      <td>-233.000</td>\n",
       "      <td>-233.000</td>\n",
       "      <td>462.00</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>281.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>-148.00</td>\n",
       "      <td>281.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.900</td>\n",
       "      <td>31.6</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>19.80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>8.820</td>\n",
       "      <td>2.300</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>...</td>\n",
       "      <td>299.00</td>\n",
       "      <td>-243.000</td>\n",
       "      <td>-243.000</td>\n",
       "      <td>299.00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>9.53</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-12.40</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>45.2</td>\n",
       "      <td>27.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>34.800</td>\n",
       "      <td>-5.790</td>\n",
       "      <td>3.060</td>\n",
       "      <td>41.400</td>\n",
       "      <td>5.52</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>38.100</td>\n",
       "      <td>38.100</td>\n",
       "      <td>12.00</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>23.90</td>\n",
       "      <td>23.90</td>\n",
       "      <td>-17.60</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>32.400</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>30.80</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1.640</td>\n",
       "      <td>-2.030</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.70</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.218</td>\n",
       "      <td>-21.70</td>\n",
       "      <td>95.2</td>\n",
       "      <td>-19.90</td>\n",
       "      <td>47.20</td>\n",
       "      <td>47.20</td>\n",
       "      <td>-19.90</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>16.300</td>\n",
       "      <td>31.3</td>\n",
       "      <td>-284.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>23.9</td>\n",
       "      <td>4.200</td>\n",
       "      <td>1.090</td>\n",
       "      <td>4.460</td>\n",
       "      <td>4.720</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>594.00</td>\n",
       "      <td>-324.000</td>\n",
       "      <td>-324.000</td>\n",
       "      <td>594.00</td>\n",
       "      <td>-35.5</td>\n",
       "      <td>142.00</td>\n",
       "      <td>-59.80</td>\n",
       "      <td>-59.80</td>\n",
       "      <td>142.00</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>-0.547</td>\n",
       "      <td>28.3</td>\n",
       "      <td>-259.0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>26.7</td>\n",
       "      <td>9.080</td>\n",
       "      <td>6.900</td>\n",
       "      <td>12.700</td>\n",
       "      <td>2.030</td>\n",
       "      <td>4.64</td>\n",
       "      <td>...</td>\n",
       "      <td>370.00</td>\n",
       "      <td>-160.000</td>\n",
       "      <td>-160.000</td>\n",
       "      <td>370.00</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-169.00</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-169.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>16.800</td>\n",
       "      <td>19.9</td>\n",
       "      <td>-288.0</td>\n",
       "      <td>8.34</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.460</td>\n",
       "      <td>1.580</td>\n",
       "      <td>-16.000</td>\n",
       "      <td>1.690</td>\n",
       "      <td>4.74</td>\n",
       "      <td>...</td>\n",
       "      <td>124.00</td>\n",
       "      <td>-27.600</td>\n",
       "      <td>-27.600</td>\n",
       "      <td>124.00</td>\n",
       "      <td>-656.0</td>\n",
       "      <td>552.00</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>552.00</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>27.000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.9</td>\n",
       "      <td>4.990</td>\n",
       "      <td>1.950</td>\n",
       "      <td>6.210</td>\n",
       "      <td>3.490</td>\n",
       "      <td>-3.51</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.810</td>\n",
       "      <td>1.810</td>\n",
       "      <td>1.95</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>22.80</td>\n",
       "      <td>22.80</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows Ã— 2549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a   \n",
       "0          4.620      30.3    -356.0     15.60      26.3       1.070  \\\n",
       "1         28.800      33.1      32.0     25.80      22.8       6.550   \n",
       "2          8.900      29.4    -416.0     16.70      23.7      79.900   \n",
       "3         14.900      31.6    -143.0     19.80      24.3      -0.584   \n",
       "4         28.300      31.3      45.2     27.30      24.5      34.800   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "2127      32.400      32.2      32.2     30.80      23.4       1.640   \n",
       "2128      16.300      31.3    -284.0     14.30      23.9       4.200   \n",
       "2129      -0.547      28.3    -259.0     15.80      26.7       9.080   \n",
       "2130      16.800      19.9    -288.0      8.34      26.0       2.460   \n",
       "2131      27.000      32.0      31.8     25.00      28.9       4.990   \n",
       "\n",
       "      mean_d_1_a  mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b   \n",
       "0          0.411     -15.700       2.060        3.15  ...      23.50  \\\n",
       "1          1.680       2.880       3.830       -4.82  ...     -23.30   \n",
       "2          3.360      90.200      89.900        2.03  ...     462.00   \n",
       "3         -0.284       8.820       2.300       -1.97  ...     299.00   \n",
       "4         -5.790       3.060      41.400        5.52  ...      12.00   \n",
       "...          ...         ...         ...         ...  ...        ...   \n",
       "2127      -2.030       0.647      -0.121       -1.10  ...     -21.70   \n",
       "2128       1.090       4.460       4.720        6.63  ...     594.00   \n",
       "2129       6.900      12.700       2.030        4.64  ...     370.00   \n",
       "2130       1.580     -16.000       1.690        4.74  ...     124.00   \n",
       "2131       1.950       6.210       3.490       -3.51  ...       1.95   \n",
       "\n",
       "      fft_742_b  fft_743_b  fft_744_b  fft_745_b  fft_746_b  fft_747_b   \n",
       "0        20.300     20.300      23.50     -215.0     280.00    -162.00  \\\n",
       "1       -21.800    -21.800     -23.30      182.0       2.57     -31.60   \n",
       "2      -233.000   -233.000     462.00     -267.0     281.00    -148.00   \n",
       "3      -243.000   -243.000     299.00      132.0     -12.40       9.53   \n",
       "4        38.100     38.100      12.00      119.0     -17.60      23.90   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2127      0.218      0.218     -21.70       95.2     -19.90      47.20   \n",
       "2128   -324.000   -324.000     594.00      -35.5     142.00     -59.80   \n",
       "2129   -160.000   -160.000     370.00      408.0    -169.00     -10.50   \n",
       "2130    -27.600    -27.600     124.00     -656.0     552.00    -271.00   \n",
       "2131      1.810      1.810       1.95      110.0      -6.71      22.80   \n",
       "\n",
       "      fft_748_b  fft_749_b     label  \n",
       "0       -162.00     280.00  NEGATIVE  \n",
       "1        -31.60       2.57   NEUTRAL  \n",
       "2       -148.00     281.00  POSITIVE  \n",
       "3          9.53     -12.40  POSITIVE  \n",
       "4         23.90     -17.60   NEUTRAL  \n",
       "...         ...        ...       ...  \n",
       "2127      47.20     -19.90   NEUTRAL  \n",
       "2128     -59.80     142.00  POSITIVE  \n",
       "2129     -10.50    -169.00  NEGATIVE  \n",
       "2130    -271.00     552.00  NEGATIVE  \n",
       "2131      22.80      -6.71   NEUTRAL  \n",
       "\n",
       "[2132 rows x 2549 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 2549)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in the dataset\n"
     ]
    }
   ],
   "source": [
    "# check if there are any missing values\n",
    "is_missing = False\n",
    "for x in emotions_df.isnull().sum():\n",
    "    if x > 0:\n",
    "        is_missing = True\n",
    "        break\n",
    "if is_missing:\n",
    "    print('There are missing values in the dataset')\n",
    "else:\n",
    "    print('No missing values in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "NEUTRAL     716\n",
       "NEGATIVE    708\n",
       "POSITIVE    708\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of values in each label\n",
    "emotions_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = emotions_df.drop(['label'], axis=1).to_numpy()\n",
    "y = emotions_df[['label']].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.15)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y_train_enc = np.array(encoder.fit_transform(y_train).todense())\n",
    "y_test_enc = np.array(encoder.transform(y_test).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hubra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\hubra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hubra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neighbors\\_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Users\\hubra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_std, y_train)\n",
    "y_pred_logreg = logreg.predict(X_test_std)\n",
    "acc_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_std, y_train)\n",
    "y_pred_knn = knn.predict(X_test_std)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred_svm = svm.predict(X_test_std)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train_std, y_train)\n",
    "y_pred_dtree = dtree.predict(X_test_std)\n",
    "acc_dtree = accuracy_score(y_test, y_pred_dtree)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_std, y_train_enc)\n",
    "y_pred_xgb = xgb.predict(X_test_std)\n",
    "acc_xgb = accuracy_score(y_test_enc, y_pred_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 98.12%\n",
      "K-Nearest Neighbors Accuracy: 95.62%\n",
      "Support Vector Machine Accuracy: 96.88%\n",
      "Decision Tree Accuracy: 95.00%\n",
      "XGBoost Accuracy: 98.12%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for each classifier\n",
    "print(\"Logistic Regression Accuracy: {:.2f}%\".format(acc_logreg * 100))\n",
    "print(\"K-Nearest Neighbors Accuracy: {:.2f}%\".format(acc_knn * 100))\n",
    "print(\"Support Vector Machine Accuracy: {:.2f}%\".format(acc_svm * 100))\n",
    "print(\"Decision Tree Accuracy: {:.2f}%\".format(acc_dtree * 100))\n",
    "print(\"XGBoost Accuracy: {:.2f}%\".format(acc_xgb * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
